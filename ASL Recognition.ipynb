{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-24T04:34:12.648830Z",
     "iopub.status.busy": "2021-06-24T04:34:12.646646Z",
     "iopub.status.idle": "2021-06-24T04:34:18.900824Z",
     "shell.execute_reply": "2021-06-24T04:34:18.901375Z",
     "shell.execute_reply.started": "2021-06-24T04:06:20.514795Z"
    },
    "papermill": {
     "duration": 6.271224,
     "end_time": "2021-06-24T04:34:18.901693",
     "exception": false,
     "start_time": "2021-06-24T04:34:12.630469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Image Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T04:34:18.927149Z",
     "iopub.status.busy": "2021-06-24T04:34:18.926359Z",
     "iopub.status.idle": "2021-06-24T04:35:07.141212Z",
     "shell.execute_reply": "2021-06-24T04:35:07.142075Z",
     "shell.execute_reply.started": "2021-06-24T04:16:16.610196Z"
    },
    "papermill": {
     "duration": 48.230649,
     "end_time": "2021-06-24T04:35:07.142333",
     "exception": false,
     "start_time": "2021-06-24T04:34:18.911684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60352 images belonging to 40 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagenerator = ImageDataGenerator(rescale = 1/255,\n",
    "                                        shear_range = 0.2,\n",
    "                                       zoom_range = 0.2,\n",
    "                                       rotation_range=40,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       horizontal_flip = True\n",
    ")\n",
    "\n",
    "train_set = train_datagenerator.flow_from_directory(\"../input/american-sign-language-recognition/training_set\",\n",
    "                                                    target_size = (64,64),\n",
    "                                                    batch_size = 32,color_mode=\"grayscale\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T04:35:07.168372Z",
     "iopub.status.busy": "2021-06-24T04:35:07.167646Z",
     "iopub.status.idle": "2021-06-24T04:35:08.702643Z",
     "shell.execute_reply": "2021-06-24T04:35:08.703474Z",
     "shell.execute_reply.started": "2021-06-24T04:16:23.114850Z"
    },
    "papermill": {
     "duration": 1.550498,
     "end_time": "2021-06-24T04:35:08.703766",
     "exception": false,
     "start_time": "2021-06-24T04:35:07.153268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 40 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagenerator = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "test_set = test_datagenerator.flow_from_directory(\"../input/american-sign-language-recognition/test_set\",\n",
    "                                                 target_size = (64,64),\n",
    "                                                 batch_size = 32,color_mode=\"grayscale\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T04:35:08.732224Z",
     "iopub.status.busy": "2021-06-24T04:35:08.731183Z",
     "iopub.status.idle": "2021-06-24T04:35:08.735487Z",
     "shell.execute_reply": "2021-06-24T04:35:08.736111Z",
     "shell.execute_reply.started": "2021-06-24T04:16:26.338789Z"
    },
    "papermill": {
     "duration": 0.021609,
     "end_time": "2021-06-24T04:35:08.736277",
     "exception": false,
     "start_time": "2021-06-24T04:35:08.714668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grayscale'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.color_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making CNN Model for Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T04:35:08.767443Z",
     "iopub.status.busy": "2021-06-24T04:35:08.766758Z",
     "iopub.status.idle": "2021-06-24T04:35:11.625236Z",
     "shell.execute_reply": "2021-06-24T04:35:11.624662Z",
     "shell.execute_reply.started": "2021-06-24T04:16:30.811696Z"
    },
    "papermill": {
     "duration": 2.87892,
     "end_time": "2021-06-24T04:35:11.625394",
     "exception": false,
     "start_time": "2021-06-24T04:35:08.746474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3,3), input_shape = (64,64,1), activation = 'relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "                        \n",
    "    keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "                        \n",
    "    keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Dense(512, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "                        \n",
    "    keras.layers.Dense(40, activation = 'softmax')\n",
    "                        \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T04:35:11.653714Z",
     "iopub.status.busy": "2021-06-24T04:35:11.652711Z",
     "iopub.status.idle": "2021-06-24T04:35:11.666289Z",
     "shell.execute_reply": "2021-06-24T04:35:11.666801Z",
     "shell.execute_reply.started": "2021-06-24T04:16:33.635896Z"
    },
    "papermill": {
     "duration": 0.031278,
     "end_time": "2021-06-24T04:35:11.667005",
     "exception": false,
     "start_time": "2021-06-24T04:35:11.635727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T04:35:11.692745Z",
     "iopub.status.busy": "2021-06-24T04:35:11.691978Z",
     "iopub.status.idle": "2021-06-24T04:57:14.661902Z",
     "shell.execute_reply": "2021-06-24T04:57:14.661346Z",
     "shell.execute_reply.started": "2021-06-24T04:16:36.415281Z"
    },
    "papermill": {
     "duration": 1322.984616,
     "end_time": "2021-06-24T04:57:14.662058",
     "exception": false,
     "start_time": "2021-06-24T04:35:11.677442",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1886/1886 [==============================] - 362s 189ms/step - loss: 2.0235 - accuracy: 0.3950 - val_loss: 0.1658 - val_accuracy: 0.9605\n",
      "Epoch 2/10\n",
      "1886/1886 [==============================] - 109s 58ms/step - loss: 0.5437 - accuracy: 0.8137 - val_loss: 0.0486 - val_accuracy: 0.9933\n",
      "Epoch 3/10\n",
      "1886/1886 [==============================] - 110s 58ms/step - loss: 0.3702 - accuracy: 0.8744 - val_loss: 0.0258 - val_accuracy: 0.9965\n",
      "Epoch 4/10\n",
      "1886/1886 [==============================] - 116s 61ms/step - loss: 0.2940 - accuracy: 0.9018 - val_loss: 0.0117 - val_accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "1886/1886 [==============================] - 110s 58ms/step - loss: 0.2409 - accuracy: 0.9202 - val_loss: 0.0135 - val_accuracy: 0.9989\n",
      "Epoch 6/10\n",
      "1886/1886 [==============================] - 108s 57ms/step - loss: 0.2024 - accuracy: 0.9322 - val_loss: 0.0040 - val_accuracy: 0.9989\n",
      "Epoch 7/10\n",
      "1886/1886 [==============================] - 107s 57ms/step - loss: 0.1825 - accuracy: 0.9394 - val_loss: 0.0067 - val_accuracy: 0.9994\n",
      "Epoch 8/10\n",
      "1886/1886 [==============================] - 99s 52ms/step - loss: 0.1649 - accuracy: 0.9443 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1886/1886 [==============================] - 102s 54ms/step - loss: 0.1440 - accuracy: 0.9519 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1886/1886 [==============================] - 100s 53ms/step - loss: 0.1429 - accuracy: 0.9529 - val_loss: 7.2412e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0a15f820d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set,epochs =10, validation_data = test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the CNN model made here for the future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T04:57:24.913309Z",
     "iopub.status.busy": "2021-06-24T04:57:24.912098Z",
     "iopub.status.idle": "2021-06-24T04:57:24.971260Z",
     "shell.execute_reply": "2021-06-24T04:57:24.970657Z",
     "shell.execute_reply.started": "2021-06-24T04:32:24.039328Z"
    },
    "papermill": {
     "duration": 5.377746,
     "end_time": "2021-06-24T04:57:24.971409",
     "exception": false,
     "start_time": "2021-06-24T04:57:19.593663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"aslr.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1419.197529,
   "end_time": "2021-06-24T04:57:43.557638",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-24T04:34:04.360109",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
